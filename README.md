# BoTest

Quality of conversational agents is important as users have high expectations. Consequently, poor interactions may lead to the user abandoning the system.
In this project, we propose a framework to test the quality of conversational agents.
Our solution transforms working input that the conversational agent accurately recognises to generate divergent input examples that introduce complexity and stress the agent. 
As the divergent inputs are based on known utterances for which we have the `normal' outputs, we can assess how robust the conversational agent is to variations in the input.

* Please see an introductory video to this project here:

[![BoTest Video](https://img.youtube.com/vi/3jU-Or0fztc/0.jpg)](https://youtu.be/3jU-Or0fztc)

* Publications
** Elayne Ruane, Theo Faure, Ross Smith, Dan Bean, Julie Carson-Berndsen, Anthony Ventresque (2017): BoTest: a Framework to Test the Quality of Conversational Agents Using Divergent Input Examples. [ACM Intelligent User Interfaces (IUI)](http://iui.acm.org/2018/).
